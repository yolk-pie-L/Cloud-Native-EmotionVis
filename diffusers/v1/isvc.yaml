apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: diffusers-v1
  annotations:
    autoscaling.knative.dev/class: "hpa.autoscaling.knative.dev"
    autoscaling.knative.dev/metric: "cpu"
    autoscaling.knative.dev/target: "75"
spec:
  predictor:
    containers:
      - name: kserve-container
        image: lasylphide/diffusers:v1
        resources:
          limits:
            cpu: "12"
            memory: 24Gi
          requests:
            cpu: "12"
            memory: 24Gi
    timeout: 300